#!/usr/bin/env python3
"""
URLå¤„ç†æµç¨‹è¿½è¸ªå·¥å…·
ç›‘è§†paper_infoåœ¨å¤„ç†è¿‡ç¨‹ä¸­çš„å˜åŒ–

ä½¿ç”¨æ–¹æ³•:
    python trace_url.py <URL>
    æˆ–è€…è¿è¡Œåè¾“å…¥URL
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from zotlink.extractors.extractor_manager import ExtractorManager
from zotlink.zotero_integration import ZoteroConnector


def print_step(step_num: int, title: str, data: dict):
    """æ‰“å°å¤„ç†æ­¥éª¤"""
    print("\n" + "=" * 80)
    print(f"æ­¥éª¤ {step_num}: {title}")
    print("=" * 80)
    
    if isinstance(data, dict):
        for key, value in data.items():
            if isinstance(value, str) and len(value) > 200:
                print(f"{key}: {value[:200]}...")
            else:
                print(f"{key}: {value}")
    else:
        print(data)


async def trace_url_processing(url: str):
    """è¿½è¸ªURLçš„å®Œæ•´å¤„ç†æµç¨‹"""
    print("\n" + "ğŸ”" * 40)
    print(f"å¼€å§‹è¿½è¸ª URL: {url}")
    print("ğŸ”" * 40)
    
    extractor_manager = ExtractorManager()
    zotero_connector = ZoteroConnector()
    
    # ğŸ”§ ä¸´æ—¶ä¿®å¤ï¼šä¿å­˜åŸå§‹æ–¹æ³•å¹¶åˆ›å»ºä¿®å¤ç‰ˆæœ¬
    original_convert = zotero_connector._convert_to_zotero_format
    
    def patched_convert_to_zotero_format(paper_info):
        """ä¿®å¤ç‰ˆæœ¬ï¼šæ”¯æŒ creators å­—æ®µ"""
        import re
        import time
        
        # è§£æä½œè€… - æ”¯æŒä¸¤ç§æ ¼å¼
        authors = []
        
        # ğŸ†• ä¼˜å…ˆä½¿ç”¨å·²ç»æ ¼å¼åŒ–çš„ creatorsï¼ˆZoteroæ ¼å¼æ•°ç»„ï¼‰
        if paper_info.get('creators') and isinstance(paper_info['creators'], list):
            print("  âœ… æ£€æµ‹åˆ° creators å­—æ®µï¼ˆZoteroæ ¼å¼ï¼‰ï¼Œç›´æ¥ä½¿ç”¨")
            authors = paper_info['creators'][:15]  # é™åˆ¶ä½œè€…æ•°é‡
        
        # å¦åˆ™è§£æ authors å­—ç¬¦ä¸²æ ¼å¼
        elif paper_info.get('authors'):
            print("  âœ… æ£€æµ‹åˆ° authors å­—æ®µï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰ï¼Œå¼€å§‹è§£æ")
            # è°ƒç”¨åŸå§‹æ–¹æ³•æ¥è§£æå­—ç¬¦ä¸²æ ¼å¼çš„ä½œè€…
            return original_convert(paper_info)
        
        else:
            print("  âš ï¸ æœªæ‰¾åˆ° authors æˆ– creators å­—æ®µ")
        
        # å¦‚æœä½¿ç”¨äº† creatorsï¼Œéœ€è¦æ‰‹åŠ¨æ„å»ºå…¶ä»–éƒ¨åˆ†
        # è§£ææ—¥æœŸ
        date = paper_info.get('date', '')
        if date and date != 'æœªçŸ¥æ—¥æœŸ':
            try:
                date_match = re.search(r'(\d{1,2})\s+(\w+)\s+(\d{4})', date)
                if date_match:
                    day, month_name, year = date_match.groups()
                    months = {
                        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04',
                        'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08',
                        'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'
                    }
                    month = months.get(month_name[:3], '01')
                    date = f"{year}-{month}-{day.zfill(2)}"
                elif re.search(r'(\d{4})[-/](\d{1,2})[-/](\d{1,2})', date):
                    pass
                elif re.search(r'^\d{4}$', date):
                    date = f"{date}-01-01"
            except:
                pass
        
        # ç¡®å®šé¡¹ç›®ç±»å‹
        item_type = paper_info.get('itemType', 'journalArticle')
        if 'arxiv.org' in paper_info.get('url', ''):
            item_type = 'preprint'
        
        # æ„å»ºZoteroé¡¹ç›®
        zotero_item = {
            "itemType": item_type,
            "title": paper_info.get('title', ''),
            "creators": authors,
            "abstractNote": paper_info.get('abstractNote') or paper_info.get('abstract', ''),
            "url": paper_info.get('url', ''),
            "date": date
        }
        
        # æ·»åŠ å…¶ä»–å­—æ®µ
        if paper_info.get('DOI'):
            zotero_item["DOI"] = paper_info['DOI']
        if paper_info.get('repository'):
            zotero_item["repository"] = paper_info['repository']
        if paper_info.get('libraryCatalog'):
            zotero_item["libraryCatalog"] = paper_info['libraryCatalog']
        
        zotero_item["accessDate"] = time.strftime('%Y-%m-%d')
        
        # ç§»é™¤ç©ºå€¼
        zotero_item = {k: v for k, v in zotero_item.items() if v}
        
        return zotero_item
    
    # åº”ç”¨ä¿®å¤
    zotero_connector._convert_to_zotero_format = patched_convert_to_zotero_format
    print("âœ… å·²åº”ç”¨ä¸´æ—¶ä¿®å¤ï¼ˆæ”¯æŒ creators å­—æ®µï¼‰\n")
    
    # æ­¥éª¤1: æå–å…ƒæ•°æ®
    print("\nâ³ æ­£åœ¨æå–å…ƒæ•°æ®...")
    
    if 'arxiv.org' in url:
        print("   æ£€æµ‹åˆ° arXiv URLï¼Œä½¿ç”¨ä¸“ç”¨æå–å™¨...")
        try:
            metadata = zotero_connector._extract_arxiv_metadata(url)
            if 'error' not in metadata:
                metadata = {
                    'title': metadata.get('title', 'Unknown'),
                    'authors': metadata.get('authors_string', ''),
                    'date': metadata.get('date', ''),
                    'abstract': metadata.get('abstract', ''),
                    'url': metadata.get('abs_url', url),
                    'pdf_url': metadata.get('pdf_url', ''),
                    'arxiv_id': metadata.get('arxiv_id', ''),
                    'extractor': 'arXivä¸“ç”¨æå–å™¨',
                    'DOI': metadata.get('doi', ''),
                }
        except Exception as e:
            print(f"âŒ æå–å¤±è´¥: {e}")
            return
    else:
        try:
            metadata = await extractor_manager.extract_metadata(url)
        except Exception as e:
            print(f"âŒ æå–å¤±è´¥: {e}")
            return
    
    print_step(1, "æå–çš„åŸå§‹å…ƒæ•°æ®", metadata)
    
    if not metadata or 'error' in metadata:
        print("\nâŒ æå–å¤±è´¥")
        return
    
    # æ­¥éª¤2: æ„å»ºåˆå§‹ paper_info
    paper_info = {
        'title': metadata.get('title', 'Unknown'),
        'url': url
    }
    
    # ğŸ”§ ä¿®å¤ï¼šåŒæ—¶å¤„ç† authors å’Œ creators å­—æ®µ
    if 'authors' in metadata:
        paper_info['authors'] = metadata['authors']
    
    if 'creators' in metadata:
        paper_info['creators'] = metadata['creators']
    
    # æ˜¾ç¤º paper_infoï¼ˆåŒ…å«ä½œè€…ä¿¡æ¯ï¼‰
    display_info = paper_info.copy()
    if 'creators' in display_info:
        # ç®€åŒ–æ˜¾ç¤ºï¼šåªæ˜¾ç¤ºä½œè€…æ•°é‡
        display_info['creators_count'] = len(display_info['creators'])
        display_info['creators_preview'] = display_info['creators'][:3]  # æ˜¾ç¤ºå‰3ä¸ª
        del display_info['creators']
    
    print_step(2, "åˆå§‹ paper_info", display_info)
    
    # æ­¥éª¤3: arXivå¢å¼ºï¼ˆå¦‚æœé€‚ç”¨ï¼‰
    if 'arxiv.org' in url:
        print("\nâ³ arXivå…ƒæ•°æ®å¢å¼º...")
        enhanced_info = zotero_connector._enhance_paper_info_for_arxiv(paper_info)
        print_step(3, "arXivå¢å¼ºåçš„ paper_info", enhanced_info)
        paper_info = enhanced_info
    
    # æ­¥éª¤3.5: æ˜¾ç¤ºä¼ é€’ç»™è½¬æ¢æ–¹æ³•çš„ paper_info
    print("\n" + "ğŸ”" * 40)
    print("æ­¥éª¤ 3.5: ä¼ é€’ç»™ _convert_to_zotero_format çš„ paper_info")
    print("ğŸ”" * 40)
    print(f"åŒ…å« 'authors' å­—æ®µ: {'authors' in paper_info}")
    print(f"åŒ…å« 'creators' å­—æ®µ: {'creators' in paper_info}")
    if 'authors' in paper_info:
        print(f"  authors (å­—ç¬¦ä¸²): {paper_info['authors'][:100]}...")
    if 'creators' in paper_info:
        print(f"  creators (æ•°ç»„): {len(paper_info['creators'])} ä½ä½œè€…")
        for i, creator in enumerate(paper_info['creators'][:3], 1):
            print(f"    ä½œè€… {i}: {creator}")
    
    # æ­¥éª¤4: è½¬æ¢ä¸ºZoteroæ ¼å¼
    print("\nâ³ è½¬æ¢ä¸ºZoteroæ ¼å¼...")
    zotero_item = zotero_connector._convert_to_zotero_format(paper_info)
    
    print_step(4, "æœ€ç»ˆçš„Zoteroæ ¼å¼", {
        'title': zotero_item.get('title'),
        'creators': zotero_item.get('creators', []),
        'date': zotero_item.get('date'),
        'url': zotero_item.get('url'),
    })
    
    # æ€»ç»“ä½œè€…ä¿¡æ¯
    print("\n" + "ğŸ“Š" * 40)
    print("ä½œè€…ä¿¡æ¯æ€»ç»“")
    print("ğŸ“Š" * 40)
    creators = zotero_item.get('creators', [])
    print(f"æœ€ç»ˆä½œè€…æ•°é‡: {len(creators)}")
    for i, creator in enumerate(creators, 1):
        print(f"  ä½œè€… {i}: {creator['firstName']} {creator['lastName']}")
    
    print("\nâœ… è¿½è¸ªå®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    # è·å–URL
    if len(sys.argv) > 1:
        url = sys.argv[1]
    else:
        print("\nè¯·è¾“å…¥è¦æµ‹è¯•çš„è®ºæ–‡URL:")
        print("ç¤ºä¾‹:")
        print("  - arXiv: https://arxiv.org/abs/2301.00001")
        print("  - bioRxiv: https://www.biorxiv.org/content/...")
        print("  - Nature: https://www.nature.com/articles/...")
        print()
        url = input("URL: ").strip()
    
    if not url:
        print("âŒ æœªæä¾›URL")
        return
    
    try:
        await trace_url_processing(url)
    except Exception as e:
        print(f"\nâŒ è¿½è¸ªè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())

